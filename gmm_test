import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

def load_data(file_path):
    data = pd.read_csv(file_path)
    return data

def prepare_multivariate_data2(data, window_size):
    seq_x = []
    targets = []

    for i in range(len(data) - window_size + 1):
        end_ix = i + window_size
        window = data[i:end_ix, :-1]
        target_window = data[i:end_ix, -1]
        target = 1 if np.any(target_window == 1) else 0
        seq_x.append(window)
        targets.append(target)

    return np.array(seq_x), np.array(targets)

def preprocess_data(data, window_size):
    labels = data['label'].values
    features = data.drop(columns=['label']).values
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)
    scaled_data = np.hstack((scaled_features, labels.reshape(-1, 1)))
    return prepare_multivariate_data2(scaled_data, window_size), scaler


import torch
import torch.nn as nn

class CNNFeatureExtractor(nn.Module):
    def __init__(self, input_length, output_features):
        super(CNNFeatureExtractor, self).__init__()
        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)
        
        # 计算全连接层的输入大小
        conv_output_size = input_length // 4  # 两次池化后的长度
        self.fc = nn.Linear(32 * conv_output_size, output_features)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.pool(x)
        x = self.relu(self.conv2(x))
        x = self.pool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x



import numpy as np
from scipy.stats import multivariate_normal

class GaussianModel:
    def __init__(self):
        self.mean = None
        self.covariance = None
        self.distribution = None

    def fit(self, X):
        self.mean = np.mean(X, axis=0)
        self.covariance = np.cov(X, rowvar=False)
        self.distribution = multivariate_normal(mean=self.mean, cov=self.covariance)

   
    def mahalanobis_distance(self, x):
        diff = x - self.mean
        md = np.sqrt(np.dot(np.dot(diff, self.inv_cov), diff.T))
        return md


import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from models.cnn_feature_extractor import CNNFeatureExtractor
from utils.data_preprocessing import load_data, preprocess_data
from utils.gaussian_model import GaussianModel
from utils.anomaly_detection import detect_anomalies
from utils.evaluation import evaluate_anomaly_detection, plot_roc_curve

# 加载和预处理数据
data = load_data('data/time_series_data.csv')
(windowed_data, labels), scaler = preprocess_data(data, window_size=10)

# 创建数据加载器
tensor_data = torch.tensor(windowed_data, dtype=torch.float32)
tensor_data = tensor_data.permute(0, 2, 1)  # 将数据调整为 [batch_size, channels, length]
dataset = TensorDataset(tensor_data, torch.tensor(labels, dtype=torch.float32))
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# 定义CNN模型
input_length = windowed_data.shape[2]  # 特征数
output_features = 10
model = CNNFeatureExtractor(input_length, output_features)
model.eval()

# 提取特征
features = []
with torch.no_grad():
    for batch in dataloader:
        batch_features = model(batch[0])
        features.append(batch_features.numpy())
features = np.vstack(features)

# 训练高斯模型，只使用正常（标签为0）的数据
normal_features = features[labels == 0]
gaussian_model = GaussianModel()
gaussian_model.fit(normal_features)

# 检测异常
threshold = -5.0  # 根据具体情况调整阈值
anomalies, anomaly_scores = detect_anomalies(features, gaussian_model, threshold)

# 评估异常检测
fpr, tpr, roc_auc = evaluate_anomaly_detection(labels, anomaly_scores)
print("AUC: ", roc_auc)

# 绘制ROC曲线
plot_roc_curve(fpr, tpr, roc_auc)

# 输出结果
print("Anomalies detected:", np.sum(anomalies))
print("Anomaly scores:", anomaly_scores)


from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

def evaluate_anomaly_detection(true_labels, anomaly_scores):
    fpr, tpr, _ = roc_curve(true_labels, anomaly_scores)
    roc_auc = auc(fpr, tpr)
    return fpr, tpr, roc_auc

def plot_roc_curve(fpr, tpr, roc_auc):
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic')
    plt.legend(loc="lower right")
    plt.show()



import numpy as np

def detect_anomalies(features, gaussian_model, threshold):
    # 计算每个样本的异常分数
    anomaly_scores = gaussian_model.score_samples(features)
    # 根据阈值检测异常
    anomalies = anomaly_scores < threshold
    return anomalies, anomaly_scores


def detect_anomalies(features, gaussian_model, threshold):
    anomaly_scores = np.array([gaussian_model.mahalanobis_distance(f) for f in features])
    anomalies = anomaly_scores > threshold
    return anomalies, anomaly_scores



# main.py
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from models.cnn_feature_extractor import CNNFeatureExtractor
from utils.data_preprocessing import load_data, preprocess_data
from sklearn.metrics import roc_curve, auc, f1_score
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal

# 定义高斯模型类
class GaussianModel:
    def __init__(self):
        self.mean = None
        self.covariance = None
        self.distribution = None

    def fit(self, X):
        self.mean = np.mean(X, axis=0)
        self.covariance = np.cov(X, rowvar=False)
        self.distribution = multivariate_normal(mean=self.mean, cov=self.covariance)

    def score_samples(self, X):
        return self.distribution.logpdf(X)

# 加载和预处理数据
data = load_data('data/time_series_data.csv')
scaled_data, labels, scaler = preprocess_data(data)

# 创建数据加载器
tensor_data = torch.tensor(scaled_data, dtype=torch.float32)
tensor_data = tensor_data.unsqueeze(1)  # 添加一个维度，使其成为单通道数据，形状变为 [batch_size, 1, length]
dataset = TensorDataset(tensor_data, torch.tensor(labels.values, dtype=torch.float32))
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# 定义CNN模型
input_length = scaled_data.shape[1]  # 特征数
output_features = 10
model = CNNFeatureExtractor(input_length, output_features)
model.eval()

# 提取特征
features = []
with torch.no_grad():
    for batch in dataloader:
        batch_features = model(batch[0])
        features.append(batch_features.numpy())
features = np.vstack(features)

# 训练高斯模型，只使用正常（标签为0）的数据
normal_features = features[labels == 0]
gaussian_model = GaussianModel()
gaussian_model.fit(normal_features)

# 检测异常并计算异常分数
anomaly_scores = gaussian_model.score_samples(features)

# 定义评估函数
def evaluate_thresholds(true_labels, anomaly_scores, percentiles):
    f1_scores = []
    for percentile in percentiles:
        threshold = np.percentile(anomaly_scores, percentile)
        predicted_labels = np.where(anomaly_scores > threshold, 1, 0)
        f1 = f1_score(true_labels, predicted_labels)
        f1_scores.append(f1)
    return f1_scores

# 选择候选的百分位数
percentiles = np.arange(90, 100, 0.5)  # 从90%到100%，步长为0.5%

# 评估不同百分位数下的性能
f1_scores = evaluate_thresholds(labels, anomaly_scores, percentiles)
best_percentile_index = np.argmax(f1_scores)
best_percentile = percentiles[best_percentile_index]
best_f1_score = f1_scores[best_percentile_index]

print("Best percentile: ", best_percentile)
print("Best F1 score: ", best_f1_score)

# 使用最佳百分位数计算阈值
best_threshold = np.percentile(anomaly_scores, best_percentile)

# 根据最佳阈值检测异常
anomalies = anomaly_scores > best_threshold
anomalies_labels = np.where(anomalies, 1, 0)

# 评估异常检测
def evaluate_anomaly_detection(true_labels, predicted_labels):
    fpr, tpr, _ = roc_curve(true_labels, predicted_labels)
    roc_auc = auc(fpr, tpr)
    return fpr, tpr, roc_auc

fpr, tpr, roc_auc = evaluate_anomaly_detection(labels, anomalies_labels)
print("AUC: ", roc_auc)

# 绘制ROC曲线
def plot_roc_curve(fpr, tpr, roc_auc):
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic')
    plt.legend(loc="lower right")
    plt.show()

plot_roc_curve(fpr, tpr, roc_auc)

# 输出结果
print("Anomalies detected:", np.sum(anomalies_labels))
print("Anomaly scores:", anomaly_scores)



